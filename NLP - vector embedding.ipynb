{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d3192e-0725-466b-8c00-7008f1fd9785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário\n",
      " ['Com', 'a', 'abrir', 'chave', 'mão', 'na', 'porta', 'quer'] \n",
      "\n",
      "Matriz\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]] \n",
      "\n",
      "Atributos\n",
      " ['x0_Com' 'x0_a' 'x0_abrir' 'x0_chave' 'x0_mão' 'x0_na' 'x0_porta'\n",
      " 'x0_quer']\n"
     ]
    }
   ],
   "source": [
    "#one-hot encoding\n",
    "#vetores de dimensão do tamanho do vocabulário - valores binários\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "X = [[\"Com\"], [\"a\"], [\"chave\"], [\"na\"], [\"mão\"], [\"quer\"], [\"abrir\"], [\"a\"], [\"porta\"]]\n",
    "\n",
    "enc.fit(X)\n",
    "\n",
    "vocab = list(enc.categories_[0])\n",
    "vetores = enc.transform(X).toarray()\n",
    "\n",
    "print(\"Vocabulário\\n\", vocab, \"\\n\")\n",
    "print(\"Matriz\\n\", vetores, \"\\n\")\n",
    "\n",
    "print(\"Atributos\\n\", enc.get_feature_names_out()) # mesma ordem de vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f402e5-1226-480e-9924-267d9d1acdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\barba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#matriz frequência termo-documento (bag of words)\n",
    "#a contagem de quantas vezes um termo aparece em um documento\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21200536-663b-4695-9b6d-3dc1b5f05bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "poema = ['E agora, José?', 'A festa acabou', 'a luz apagou', 'o povo sumiu', 'a noite esfriou', 'e agora, José?', 'e agora, você?',\n",
    "         'você que é sem nome', 'que zomba dos outros', 'você que faz versos', 'que ama, protesta?', 'e agora, José?']\n",
    "print(len(poema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f322952-b2d9-4497-9015-29cf764f8bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário\n",
      " [',' '?' 'a' 'acabou' 'agora' 'ama' 'apagou' 'dos' 'e' 'esfriou' 'faz'\n",
      " 'festa' 'josé' 'luz' 'noite' 'nome' 'o' 'outros' 'povo' 'protesta' 'que'\n",
      " 'sem' 'sumiu' 'versos' 'você' 'zomba' 'é'] \n",
      "\n",
      "Matriz\n",
      " [[1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0]\n",
      " [1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      " [1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barba\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def tokenize(texto):\n",
    "    return nltk.word_tokenize(texto, language=\"portuguese\")\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize, lowercase=True)\n",
    "\n",
    "vetores = vectorizer.fit_transform(poema)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Vocabulário\\n\", vocab, \"\\n\")\n",
    "print(\"Matriz\\n\", vetores.toarray(), \"\\n\") #importante notar que essa representação não é binária!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc84f4de-9462-44dd-8d9c-d157971818ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário\n",
      " ['a', 'acabou', 'agora', 'ama', 'apagou', 'dos', 'é', 'esfriou', 'faz', 'festa', 'josé', 'luz', 'noite', 'nome', 'o', 'outros', 'povo', 'protesta', 'que', 'sem', 'sumiu', 'versos', 'você', 'zomba', 'é'] \n",
      "\n",
      "Matriz\n",
      " [[ 0.  1.  4.  1.  1.  1.  3.  1.  1.  1.  3.  1.  1.  0. 10.  1.  0.  1.\n",
      "   3.  0.  0.  1.  2.  1.  3.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 4.  0.  0.  0.  0.  0.  3.  0.  0.  0.  3.  0.  0.  0.  4.  0.  0.  0.\n",
      "   0.  0.  0.  0.  1.  0.  3.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.\n",
      "   1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.\n",
      "   1.  0.  0.  0.  0.  1.  0.]\n",
      " [ 3.  0.  3.  0.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1.  4.  0.  0.  0.\n",
      "   1.  1.  0.  0.  1.  0.  4.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   1.  0.  0.  1.  1.  0.  0.]\n",
      " [ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 3.  0.  3.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  3.]\n",
      " [ 1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   1.  1.  0.  0.  1.  0.  1.]\n",
      " [10.  1.  4.  1.  1.  1.  4.  1.  1.  1.  3.  1.  1.  1.  0.  1.  1.  1.\n",
      "   4.  1.  1.  1.  3.  1.  4.]\n",
      " [ 1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 3.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  0.  1.  4.  1.  0.  1.\n",
      "   0.  1.  0.  1.  2.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.\n",
      "   1.  0.  0.  0.  1.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   1.  0.  0.  0.  1.  0.  0.]\n",
      " [ 2.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  3.  0.  0.  0.\n",
      "   2.  1.  0.  1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 3.  0.  3.  0.  0.  0.  4.  0.  0.  0.  3.  0.  0.  1.  4.  0.  0.  0.\n",
      "   1.  1.  0.  0.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#matriz de frequência termo-termo\n",
    "#quantas vezes um termo aparece acompanhado de outro no mesmo documento\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "corpus_tok = []\n",
    "for verso in poema:\n",
    "    tokenizado = str(tokenize(verso.lower()))\n",
    "    corpus_tok.append(tokenizado)\n",
    "\n",
    "vocab = ['a', 'acabou', 'agora', 'ama', 'apagou', 'dos', 'é', 'esfriou', 'faz', 'festa', \n",
    "         'josé', 'luz', 'noite', 'nome', 'o', 'outros', 'povo', 'protesta', 'que', 'sem', \n",
    "         'sumiu', 'versos', 'você', 'zomba', 'é']\n",
    "\n",
    "vetores = np.zeros((len(vocab), len(vocab)))\n",
    "\n",
    "for verso in corpus_tok:\n",
    "    for i, w1 in enumerate(vocab):\n",
    "        for j, w2 in enumerate(vocab):\n",
    "            if i != j:\n",
    "                if w1 in verso and w2 in verso:\n",
    "                    vetores[i, j] += 1\n",
    "\n",
    "print(\"Vocabulário\\n\", vocab, \"\\n\")\n",
    "print(\"Matriz\\n\", vetores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "530256e1-dbc8-4e67-a90b-40125a03542d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário\n",
      " ['acabou' 'agora' 'ama' 'apagou' 'esfriou' 'faz' 'festa' 'josé' 'luz'\n",
      " 'noite' 'nome' 'outros' 'povo' 'protesta' 'sumiu' 'versos' 'zomba'] \n",
      "\n",
      "Matriz\n",
      " [[0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\barba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#remoção de stopwords\n",
    "#para reduzir a esparsidade da representação\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=stopwords)\n",
    "\n",
    "vetor = vectorizer.fit_transform(poema)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Vocabulário\\n\", vocab, \"\\n\")\n",
    "print(\"Matriz\\n\", vetor.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488cf9d4-144b-4b7b-8bb1-6eb0dd698228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulário\n",
      " ['acabou' 'agora' 'ama' 'apagou' 'dos' 'esfriou' 'faz' 'festa' 'josé'\n",
      " 'luz' 'noite' 'nome' 'outros' 'povo' 'protesta' 'que' 'sem' 'sumiu'\n",
      " 'versos' 'você' 'zomba'] \n",
      "\n",
      "Matriz\n",
      " [[0.   0.67 0.   0.   0.   0.   0.   0.   0.74 0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.71 0.   0.   0.   0.   0.   0.   0.71 0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.71 0.   0.   0.   0.   0.   0.71 0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.71\n",
      "  0.   0.   0.   0.71 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.71 0.   0.   0.   0.   0.71 0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.67 0.   0.   0.   0.   0.   0.   0.74 0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.67 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.74 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.57 0.   0.\n",
      "  0.   0.39 0.57 0.   0.   0.44 0.  ]\n",
      " [0.   0.   0.   0.   0.54 0.   0.   0.   0.   0.   0.   0.   0.54 0.\n",
      "  0.   0.37 0.   0.   0.   0.   0.54]\n",
      " [0.   0.   0.   0.   0.   0.   0.57 0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.39 0.   0.   0.57 0.44 0.  ]\n",
      " [0.   0.   0.64 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.64 0.43 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.67 0.   0.   0.   0.   0.   0.   0.74 0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "#matriz tf-idf\n",
    "#quantas vezes um termo aparece em um número total de documentos\n",
    "#e em relação ao tamanho do documento que está sendo levado em consideração\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "vectorizer = Pipeline([\n",
    "    ('count', CountVectorizer()),\n",
    "    ('tfid', TfidfTransformer())\n",
    "])\n",
    "\n",
    "vectors = vectorizer.fit_transform(poema)\n",
    "vocab = vectorizer['count'].get_feature_names_out()\n",
    "\n",
    "print(\"Vocabulário\\n\", vocab, \"\\n\")\n",
    "print(\"Matriz\\n\", np.round(vectors.toarray(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9959014-6f3e-4d01-a4b0-93bf31b5293a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
